#! /usr/bin/env nix-shell
#! nix-shell -i python3 -p python35Packages.GitPython python35Packages.aiohttp python35Packages.toolz python35Packages.unidecode
import asyncio
import datetime
import itertools
import json
import logging
import os
import tempfile
from xmlrpc.client import ServerProxy

import aiohttp
import toolz
from git import Repo
from unidecode import unidecode

URL_REPO = "https://github.com/FRidh/srcs-pypi";

#INDEX = "http://pypi.python.org/pypi"
INDEX = "https://pypi.io/pypi"
"""url of PyPI"""

EXTENSIONS = ['tar.gz', 'tar.bz2', 'tar', 'zip', 'whl']
"""Permitted file extensions. These are evaluated from left to right and the first occurance is returned."""

INCLUDE_NO_VERSIONS_AVAILABLE = False
"""Whether to include the package when no versions are available. Could still be useful for the meta-data."""

FOLDER_DATA = 'data'
FILE_TIMESTAMP = os.path.join(FOLDER_DATA, "timestamp")

logger = logging.getLogger(__name__)

NSEMAPHORE = 200
"""Maximum amount of concurrent requests"""

NCHARACTERS = 1
"""Group the packages on the first characters"""

NTIMEOUT = 2
"""Timeout in seconds"""

def _file(package):
    """Full path to file of `package`.
    """
    return os.path.join('data', package[0], "{}.json".format(package))


def retrieve_available_packages(index=INDEX):
    """Retrieve a list with available packages from the index.

    :param index: url with packages index. By default `INDEX` is used.
    :returns: List of packages.
    """
    with ServerProxy(index) as client:
        return client.list_packages()


def retrieve_packages_to_update(timestamp, index=INDEX):
    """Obtain names of packages that have updated since we last checked PyPI.

    :param timestamp: UTC timestamp.
    :param index: url with packages index. By default `INDEX` is used.
    :returns: List of packages.
    """
    with ServerProxy(index) as client:
        # List of tuples with changes.
        # The last change is the last item in the list.
        # Tuple of (package name, version, timestamp, event)
        # If changelog is passed True as second argument
        # a fifth item is added, serial.
        changes = client.changelog(timestamp)
    timestamp_last_update = changes[-1][2]
    packages = list(set([x[0] for x in changes]))
    return packages, timestamp_last_update


async def _fetch_page(session, url, sem):
    """Fetch page asynchronously.

    :param session: Session of client
    :param url: Requested url
    """
    async with sem:
        async with session.get(url) as response:
            with aiohttp.Timeout(NTIMEOUT):
                async with session.get(url) as response:
                    assert response.status == 200
                    return await response.json()


async def _write_package(folder, package, data):
    """Write JSON to file."""
    # We group files on first character of name.
    first_characters = package[:NCHARACTERS]
    if not os.path.exists(os.path.join(folder, first_characters)):
        os.makedirs(os.path.join(folder, first_characters))

    with open(os.path.join(folder, first_characters, "{}.json".format(package)), 'w') as f:
        json.dump(data, f, indent=2, sort_keys=True)

async def _retrieve_and_write(session, semaphore, index, folder, package):
    url = "{}/{}/json".format(index, package)
    json = await _fetch_page(session, url, semaphore)
    name, data = await extract_relevant_nix_data(json)
    await _write_package(folder, package, data)
    logger.debug("Finished with {}".format(package))

async def _all(session, semaphore, index, folder, packages):
    tasks = [ asyncio.ensure_future(_retrieve_and_write(session, semaphore, index, folder, package)) for package in packages]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return results


def _get_and_write_data(folder, packages, index=INDEX):
    """Yield JSON information obtained from PyPI index given an iterable of package names.

    :param packages: Iterable of package names.
    :param index: url with packages index. By default `INDEX` is used.
    """
    loop = asyncio.get_event_loop()
    connector = aiohttp.TCPConnector(share_cookies=True, loop=loop)
    with aiohttp.ClientSession(loop=loop, connector=connector) as session:
        tasks = []
        sem = asyncio.Semaphore(NSEMAPHORE)
        result = loop.run_until_complete(_all(session, sem, index, folder, packages))
        logger.info("Finished retrieved JSON from PyPI")
    loop.close()


def _clean_string(s):
    """Clean string. Remove unicode characters.
    """
    return unidecode(s)

async def extract_relevant_nix_data(json):
    """Extract relevant Nix data from the JSON of a package obtained from PyPI.

    :param json: JSON obtained from PyPI
    :param version: Specific version of package or one of the following strings: ['release',]
    """
    def _extract_license(json):
        """Extract license from JSON."""
        return json['info']['license']

    def _available_versions(json):
        return json['releases'].keys()

    def _extract_latest_version(json):
        return json['info']['version']

    def _get_src_and_hash(json, version, extensions):
        """Obtain url and hash for a given version and list of allowable extensions."""
        if not json['releases']:
            msg = "Package {}: No releases available.".format(json['info']['name'])
            raise ValueError(msg)
        else:
            # We use ['releases'] and not ['urls'] because we want to have the possibility for different version.
            for extension in extensions:
                for possible_file in json['releases'][version]:
                    if possible_file['filename'].endswith(extension):
                        src = {'url': str(possible_file['url']),
                               'sha256': str(possible_file['digests']['sha256']),
                                }
                        return src
            else:
                msg = "Package {}: No release for version {} with valid file extension available.".format(json['info']['name'], version)
                logger.info(msg)
                return None
                #raise ValueError(msg)

    def _get_sources(json, extensions):
        versions = _available_versions(json)
        releases = {version: _get_src_and_hash(json, version, extensions) for version in versions}
        releases = toolz.itemfilter(lambda x: x[1] is not None, releases)
        return releases

    name = _clean_string(str(json['info']['name']))
    latest_version = str(_extract_latest_version(json))
    sources = _get_sources(json, EXTENSIONS)

    # Collect meta data
    license = _clean_string(str(_extract_license(json)))
    summary = _clean_string(str(json['info'].get('summary')).strip('.'))
    homepage = _clean_string(str(json['info'].get('home_page')))

    meta = dict()
    if license != "UNKNOWN":
        meta['license'] = license

    if summary != "UNKNOWN":
        meta['description'] = summary

    if homepage is not None:
        meta['homepage'] = homepage

    data = dict()
    data['latest_version'] = latest_version,
    data['versions'] = sources
    data['meta'] = meta

    return name, data


def main():
    logging.basicConfig(filename='pypi2json.log', level=logging.DEBUG, filemode='w')

    with tempfile.TemporaryDirectory() as folder:
        # Clone repository from url into repo folder.
        repo = Repo.clone_from(URL_REPO, folder)

        if not os.path.exists(os.path.join(folder, FOLDER_DATA)):
            os.makedirs(os.path.join(folder, FOLDER_DATA))

        # Check whether we update JSON file or create new one.
        update = os.path.isfile(os.path.join(folder, FILE_TIMESTAMP))

        # Obtain list of packages to update/retrieve
        if update:
            with open(os.path.join(folder, FILE_TIMESTAMP), 'r') as f:
                timestamp = float(f.readline())
            packages, timestamp = retrieve_packages_to_update(timestamp)
        else:
            packages = retrieve_available_packages()
            timestamp = datetime.datetime.now().timestamp()

        with open(os.path.join(folder, FILE_TIMESTAMP), 'w') as f:
            f.write(str(timestamp))

        npackages = len(packages)
        logging.info("Updating {} packages.".format(npackages))

        # Get data of each package and write to file
        _get_and_write_data(os.path.join(folder, FOLDER_DATA), packages)

        print(os.listdir(os.path.join(folder, FOLDER_DATA)))


        # Add updated JSON file to staging and commit
        repo.index.add([os.path.join(folder, FOLDER_DATA)])
        repo.index.commit('Update')
        repo.remote().push()


if __name__ == '__main__':
    main()
